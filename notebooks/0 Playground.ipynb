{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = xr.open_dataset('data/julia2018/timeseries_dosenbach2010.nc5')['subject'].values\n",
    "subject_encoder = LabelEncoder().fit(subjects)\n",
    "class_encoder = LabelEncoder().fit([subj[:4] for subj in subjects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time-series and concatenate them along the regions dimension\n",
    "\n",
    "def get_atlas_name(file_name):\n",
    "    name = file_name.replace('-','_').replace('_2mm','')\n",
    "    name = name.replace('difumo_','difumo')\n",
    "    return name.split('_', 1)[1]\n",
    "\n",
    "ts_files = {\n",
    "    get_atlas_name(f.stem): f\n",
    "    for f in Path('data/julia2018/').glob('*.nc5')\n",
    "}\n",
    "\n",
    "X_region = []\n",
    "y_subject = []\n",
    "y_class = []\n",
    "\n",
    "s = 0\n",
    "\n",
    "\n",
    "for atlas_name, ts_file in tqdm(ts_files.items()):\n",
    "\n",
    "    ds = xr.open_dataset(ts_file).map(lambda x: x.values)\n",
    "\n",
    "    # time-series\n",
    "    ts = torch.tensor(ds['timeseries'].values).to(torch.float32)\n",
    "    ts = ts.permute(0, 2, 1)  # (n_subjects, n_regions, n_timepoints)\n",
    "    X_region.append(ts)\n",
    "\n",
    "X_regions = torch.cat(X_region, dim=1)\n",
    "\n",
    "# subjects\n",
    "subjects = subject_encoder.transform(ds['subject'].values)\n",
    "y_subject = torch.tensor(subjects)  # (n_subjects, n_regions)\n",
    "\n",
    "# classes\n",
    "classes = class_encoder.transform(ds['subject'].values)\n",
    "y_class = torch.tensor(classes)  # (n_subjects, n_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ACNets(pl.LightningModule):\n",
    "    def __init__(self, input_size, feature_size, hidden_size, n_timesteps, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.example_input_array = torch.Tensor(32, 948, 125)\n",
    "\n",
    "        self.feature_extractor = nn.Conv1d(input_size, feature_size, kernel_size)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=feature_size, hidden_size=hidden_size,\n",
    "            num_layers=n_timesteps - kernel_size + 1, batch_first=True)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=hidden_size, hidden_size=feature_size,\n",
    "            num_layers=n_timesteps - kernel_size + 1, batch_first=True)\n",
    "\n",
    "        self.loss_recon = nn.MSELoss()\n",
    "        self.loss_class = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        # out = out.squeeze(1)\n",
    "\n",
    "        x_enc = x.permute(0, 2, 1)  # permute to batch, time, feature\n",
    "        \n",
    "        y_enc, (h_enc, _) = self.encoder(x_enc)\n",
    "        x_recon, (h_dec, _) = self.decoder(h_enc.permute(1, 0, 2))  # permute to batch, time, feature\n",
    "\n",
    "        # classification output\n",
    "        y_cls = self.fc(h_enc[-1, :, :])  # select last state\n",
    "\n",
    "        return x_enc, x_recon, y_cls\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y  = batch\n",
    "        x_enc, x_recon, y_hat = self(x)\n",
    "        loss_recon = self.loss_recon(x_recon, x_enc)\n",
    "        loss_cls = self.loss_class(y_hat, y)\n",
    "        loss = loss_recon + loss_cls\n",
    "        accuracy = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log('train/loss_recon', loss_recon)\n",
    "        self.log('train/loss_cls', loss_cls)\n",
    "        self.log('train/loss', loss)\n",
    "        self.log('train/accuracy', accuracy)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x,y  = batch\n",
    "        x_enc, x_recon, y_hat = self(x)\n",
    "        loss_recon = self.loss_recon(x_recon, x_enc)\n",
    "        loss_cls = self.loss_class(y_hat, y)\n",
    "        loss = loss_recon + loss_cls\n",
    "        accuracy = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log('val/loss_recon', loss_recon)\n",
    "        self.log('val/loss_cls', loss_cls)\n",
    "        self.log('val/loss', loss)\n",
    "        self.log('val/accuracy', accuracy)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "class Julia2018DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        self.data = torch.utils.data.TensorDataset(self.X, self.y)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data, batch_size=32)\n",
    "\n",
    "\n",
    "datamodule = Julia2018DataModule(X_regions, y_class)\n",
    "model = ACNets(X_regions.shape[1], 64, hidden_size=48, n_timesteps=X_regions.shape[2])\n",
    "trainer = pl.Trainer(max_epochs=10000, accelerator='cpu', log_every_n_steps=1, logger=True)\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "X_regions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnets-multihead",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = xr.open_dataset('data/julia2018/timeseries_dosenbach2010.nc5')['subject'].values\n",
    "subject_encoder = LabelEncoder().fit(subjects)\n",
    "class_encoder = LabelEncoder().fit([subj[:4] for subj in subjects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c8707ba706427c853a2a7a1c7f32f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load time-series and concatenate them along the regions dimension\n",
    "\n",
    "def get_atlas_name(file_name):\n",
    "    name = file_name.replace('-','_').replace('_2mm','')\n",
    "    name = name.replace('difumo_','difumo')\n",
    "    return name.split('_', 1)[1]\n",
    "\n",
    "ts_files = {\n",
    "    get_atlas_name(f.stem): f\n",
    "    for f in Path('data/julia2018/').glob('*.nc5')\n",
    "}\n",
    "\n",
    "X_region = []\n",
    "y_subject = []\n",
    "y_class = []\n",
    "\n",
    "s = 0\n",
    "\n",
    "\n",
    "for atlas_name, ts_file in tqdm(ts_files.items()):\n",
    "\n",
    "    ds = xr.open_dataset(ts_file).map(lambda x: x.values)\n",
    "\n",
    "    # time-series\n",
    "    ts = torch.tensor(ds['timeseries'].values).to(torch.float32)\n",
    "    ts = ts.permute(0, 2, 1)  # (n_subjects, n_regions, n_timepoints)\n",
    "    X_region.append(ts)\n",
    "\n",
    "    # subjects\n",
    "    subjects = subject_encoder.transform(ds['subject'].values)\n",
    "    subjects = torch.tensor(subjects).reshape(-1, 1).repeat(1, ts.shape[1])  # (n_subjects, n_regions)\n",
    "    y_subject.append(subjects)\n",
    "\n",
    "    # classes\n",
    "    classes = class_encoder.transform(ds['subject'].values)\n",
    "    classes = torch.tensor(classes).reshape(-1, 1).repeat(1, ts.shape[1])  # (n_subjects, n_regions)\n",
    "    y_class.append(classes)\n",
    "\n",
    "\n",
    "X_regions = torch.cat(X_region, dim=1)\n",
    "y_subject = torch.cat(y_subject, dim=1)\n",
    "y_class = torch.cat(y_class, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 948, 124]), torch.Size([192]), torch.Size([192]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_regions.shape, y_subject.shape, y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mtrain_dataloader\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m---> 46\u001b[0m datamodule \u001b[39m=\u001b[39m Julia2018DataModule(X_regions, y_subject)\n\u001b[1;32m     48\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m     49\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, datamodule\u001b[39m=\u001b[39mdatamodule)\n",
      "Cell \u001b[0;32mIn[134], line 40\u001b[0m, in \u001b[0;36mJulia2018DataModule.__init__\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m X\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m y\n\u001b[0;32m---> 40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mTensorDataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my)\n",
      "File \u001b[0;32m~/micromamba/envs/acnets-multihead/lib/python3.10/site-packages/torch/utils/data/dataset.py:192\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "\u001b[0;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class ACNets(pl.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Conv1d(948, 1, 3)\n",
    "        self.fc = nn.Linear(122,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feature_extractor(x)\n",
    "        print('[1]', out.shape)\n",
    "        out = out.squeeze(1)\n",
    "        print('[2]', out.shape)\n",
    "        out = self.fc(out)\n",
    "        out = nn.functional.softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y  = batch\n",
    "        y_hat = self(x)\n",
    "        print(y.shape, y_hat.shape)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "model = ACNets()\n",
    "\n",
    "class Julia2018DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.data = torch.utils.data.TensorDataset(self.X, self.y)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data)\n",
    "\n",
    "\n",
    "datamodule = Julia2018DataModule(X_regions, y_subject)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "trainer.fit(model, datamodule=datamodule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acnets-multihead",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
